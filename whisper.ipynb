{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists('ffmpeg'):\n",
    "#     !git clone https://git.ffmpeg.org/ffmpeg.git ffmpeg\n",
    "\n",
    "# !cd ffmpeg && ./configure && make && make install\n",
    "\n",
    "# ffmpeg_path = os.path.join(os.getcwd(), 'ffmpeg', 'bin')\n",
    "# os.environ['PATH'] += os.pathsep + ffmpeg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"biodatlab/whisper-th-medium-combined\"  # specify the model name\n",
    "lang = \"th\"  # change to Thai langauge\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=MODEL_NAME,\n",
    "    chunk_length_s=30,\n",
    "    device=device,\n",
    ")\n",
    "pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(\n",
    "  language=lang,\n",
    "  task=\"transcribe\"\n",
    ")\n",
    "\n",
    "# pipe = pipeline(\"automatic-speech-recognition\", model=MODEL_NAME, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Device id  0  -  Microsoft Sound Mapper - Input\n",
      "Input Device id  1  -  Microphone (ATR2500x-USB Microp\n",
      "Input Device id  2  -  Microphone (NVIDIA Broadcast)\n",
      "Input Device id  3  -  Microphone Array (Realtek(R) Au\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "\n",
    "for i in range(0, numdevices):\n",
    "    if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "        print(\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microphone (ATR2500x-USB Microp is supported.\n"
     ]
    }
   ],
   "source": [
    "devinfo = p.get_device_info_by_index(1)  # Or whatever device you care about.\n",
    "if p.is_format_supported(44100.0,  # Sample rate\n",
    "                         input_device=devinfo['index'],\n",
    "                         input_channels=devinfo['maxInputChannels'],\n",
    "                         input_format=pyaudio.paInt16):\n",
    "  print(devinfo['name'] + ' is supported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Terms\n",
    "\n",
    "Stack : https://stackoverflow.com/questions/35970282/what-are-chunks-samples-and-frames-when-using-pyaudio\n",
    "\n",
    "1. \"RATE\" is the \"sampling rate\", i.e. the number of frames per second\n",
    "2. \"CHUNK\" is the (arbitrarily chosen) number of frames the (potentially very long) signals are split into in this example\n",
    "3. Yes, each frame will have 2 samples as \"CHANNELS=2\", but the term \"samples\" is seldom used in this context (because it is confusing)\n",
    "4. Yes, size of each sample is 2 bytes (= 16 bits) in this example\n",
    "5. Yes, size of each frame is 4 bytes\n",
    "6. Yes, each element of \"frames\" should be 4096 bytes. `sys.getsizeof()` reports the storage space needed by the Python interpreter, which is typically a bit more than the actual size of the raw data.\n",
    "7. `RATE * RECORD_SECONDS` is the number of frames that should be recorded. Since the `for` loop is not repeated for each frame but only for each chunk, the number of loops has to be divided by the chunk size `CHUNK`. This has nothing to do with samples, so there is no factor of `2` involved.\n",
    "8. If you really want to see the hexadecimal values, you can try something like `[hex(x) for x in frames[0]]`. If you want to get the actual 2-byte numbers use the format string `'<H'` with the struct module.\n",
    "\n",
    "You might be interested in my tutorial about reading WAV files with the wave module, which covers some of your questions in more detail: http://nbviewer.jupyter.org/github/mgeier/python-audio/blob/master/audio-files/audio-files-with-wave.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "\n",
    "MIC_INDEX = 1\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "CHUNK = 1024\n",
    "CHANNELS = 2\n",
    "FORMAT = pyaudio.paInt16\n",
    "\n",
    "RECORD_SECONDS = 3\n",
    "WAVE_OUTPUT_FILENAME = \"voice/temp.wav\"\n",
    "\n",
    "# Initialize Audio Stream\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=SAMPLE_RATE,\n",
    "    input=True,\n",
    "    frames_per_buffer=CHUNK,\n",
    "    input_device_index=MIC_INDEX,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "Saved to voice/temp.wav\n"
     ]
    }
   ],
   "source": [
    "print('Recording...')\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(SAMPLE_RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print('Finished recording.')\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(SAMPLE_RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "print('Saved to ' + WAVE_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สวัสดีครับ test ไมโครโฟน\n"
     ]
    }
   ],
   "source": [
    "text = pipe('voice/temp.wav')['text']\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
